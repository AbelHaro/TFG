&&&& RUNNING TensorRT.trtexec [TensorRT v8502] # trtexec --onnx=2024_11_28_canicas_yolo11n.onnx --saveEngine=model_gn.engine --exportProfile=model_gn.json --fp16 --useDLACore=0 --allowGPUFallback --useSpinWait --separateProfileRun
[01/23/2025-09:18:04] [I] === Model Options ===
[01/23/2025-09:18:04] [I] Format: ONNX
[01/23/2025-09:18:04] [I] Model: 2024_11_28_canicas_yolo11n.onnx
[01/23/2025-09:18:04] [I] Output:
[01/23/2025-09:18:04] [I] === Build Options ===
[01/23/2025-09:18:04] [I] Max batch: explicit batch
[01/23/2025-09:18:04] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[01/23/2025-09:18:04] [I] minTiming: 1
[01/23/2025-09:18:04] [I] avgTiming: 8
[01/23/2025-09:18:04] [I] Precision: FP32+FP16
[01/23/2025-09:18:04] [I] LayerPrecisions: 
[01/23/2025-09:18:04] [I] Calibration: 
[01/23/2025-09:18:04] [I] Refit: Disabled
[01/23/2025-09:18:04] [I] Sparsity: Disabled
[01/23/2025-09:18:04] [I] Safe mode: Disabled
[01/23/2025-09:18:04] [I] DirectIO mode: Disabled
[01/23/2025-09:18:04] [I] Restricted mode: Disabled
[01/23/2025-09:18:04] [I] Build only: Disabled
[01/23/2025-09:18:04] [I] Save engine: model_gn.engine
[01/23/2025-09:18:04] [I] Load engine: 
[01/23/2025-09:18:04] [I] Profiling verbosity: 0
[01/23/2025-09:18:04] [I] Tactic sources: Using default tactic sources
[01/23/2025-09:18:04] [I] timingCacheMode: local
[01/23/2025-09:18:04] [I] timingCacheFile: 
[01/23/2025-09:18:04] [I] Heuristic: Disabled
[01/23/2025-09:18:04] [I] Preview Features: Use default preview flags.
[01/23/2025-09:18:04] [I] Input(s)s format: fp32:CHW
[01/23/2025-09:18:04] [I] Output(s)s format: fp32:CHW
[01/23/2025-09:18:04] [I] Input build shapes: model
[01/23/2025-09:18:04] [I] Input calibration shapes: model
[01/23/2025-09:18:04] [I] === System Options ===
[01/23/2025-09:18:04] [I] Device: 0
[01/23/2025-09:18:04] [I] DLACore: 0(With GPU fallback)
[01/23/2025-09:18:04] [I] Plugins:
[01/23/2025-09:18:04] [I] === Inference Options ===
[01/23/2025-09:18:04] [I] Batch: Explicit
[01/23/2025-09:18:04] [I] Input inference shapes: model
[01/23/2025-09:18:04] [I] Iterations: 10
[01/23/2025-09:18:04] [I] Duration: 3s (+ 200ms warm up)
[01/23/2025-09:18:04] [I] Sleep time: 0ms
[01/23/2025-09:18:04] [I] Idle time: 0ms
[01/23/2025-09:18:04] [I] Streams: 1
[01/23/2025-09:18:04] [I] ExposeDMA: Disabled
[01/23/2025-09:18:04] [I] Data transfers: Enabled
[01/23/2025-09:18:04] [I] Spin-wait: Enabled
[01/23/2025-09:18:04] [I] Multithreading: Disabled
[01/23/2025-09:18:04] [I] CUDA Graph: Disabled
[01/23/2025-09:18:04] [I] Separate profiling: Enabled
[01/23/2025-09:18:04] [I] Time Deserialize: Disabled
[01/23/2025-09:18:04] [I] Time Refit: Disabled
[01/23/2025-09:18:04] [I] NVTX verbosity: 0
[01/23/2025-09:18:04] [I] Persistent Cache Ratio: 0
[01/23/2025-09:18:04] [I] Inputs:
[01/23/2025-09:18:04] [I] === Reporting Options ===
[01/23/2025-09:18:04] [I] Verbose: Disabled
[01/23/2025-09:18:04] [I] Averages: 10 inferences
[01/23/2025-09:18:04] [I] Percentiles: 90,95,99
[01/23/2025-09:18:04] [I] Dump refittable layers:Disabled
[01/23/2025-09:18:04] [I] Dump output: Disabled
[01/23/2025-09:18:04] [I] Profile: Disabled
[01/23/2025-09:18:04] [I] Export timing to JSON file: 
[01/23/2025-09:18:04] [I] Export output to JSON file: 
[01/23/2025-09:18:04] [I] Export profile to JSON file: model_gn.json
[01/23/2025-09:18:04] [I] 
[01/23/2025-09:18:04] [I] === Device Information ===
[01/23/2025-09:18:04] [I] Selected Device: Xavier
[01/23/2025-09:18:04] [I] Compute Capability: 7.2
[01/23/2025-09:18:04] [I] SMs: 8
[01/23/2025-09:18:04] [I] Compute Clock Rate: 1.377 GHz
[01/23/2025-09:18:04] [I] Device Global Memory: 30990 MiB
[01/23/2025-09:18:04] [I] Shared Memory per SM: 96 KiB
[01/23/2025-09:18:04] [I] Memory Bus Width: 256 bits (ECC disabled)
[01/23/2025-09:18:04] [I] Memory Clock Rate: 1.377 GHz
[01/23/2025-09:18:04] [I] 
[01/23/2025-09:18:04] [I] TensorRT version: 8.5.2
[01/23/2025-09:18:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +187, GPU +0, now: CPU 216, GPU 8689 (MiB)
[01/23/2025-09:18:06] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +106, GPU +101, now: CPU 344, GPU 8811 (MiB)
[01/23/2025-09:18:06] [I] Start parsing network model
[01/23/2025-09:18:06] [I] [TRT] ----------------------------------------------------------------
[01/23/2025-09:18:06] [I] [TRT] Input filename:   2024_11_28_canicas_yolo11n.onnx
[01/23/2025-09:18:06] [I] [TRT] ONNX IR version:  0.0.10
[01/23/2025-09:18:06] [I] [TRT] Opset version:    16
[01/23/2025-09:18:06] [I] [TRT] Producer name:    pytorch
[01/23/2025-09:18:06] [I] [TRT] Producer version: 2.0.0
[01/23/2025-09:18:06] [I] [TRT] Domain:           
[01/23/2025-09:18:06] [I] [TRT] Model version:    0
[01/23/2025-09:18:06] [I] [TRT] Doc string:       
[01/23/2025-09:18:06] [I] [TRT] ----------------------------------------------------------------
[01/23/2025-09:18:06] [I] Finish parsing network model
[01/23/2025-09:18:08] [I] [TRT] ---------- Layers Running on DLA ----------
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.0/conv/Conv.../model.10/m/m.0/attn/qkv/conv/Conv]}
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.10/m/m.0/attn/Split.../model.10/m/m.0/attn/Transpose]}
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.10/m/m.0/attn/Constant_1_output_0 + (Unnamed Layer* 146) [Shuffle] + /model.10/m/m.0/attn/Mul]}
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.10/m/m.0/attn/Split_20...(Unnamed Layer* 149) [Shuffle] + /model.10/m/m.0/attn/Transpose_1]}
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.10/Split]}
[01/23/2025-09:18:08] [I] [TRT] [DlaLayer] {ForeignNode[/model.10/m/m.0/attn/pe/conv/Conv.../model.23/Concat_2]}
[01/23/2025-09:18:08] [I] [TRT] ---------- Layers Running on GPU ----------
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.10/m/m.0/attn/Reshape
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] MATRIX_MULTIPLY: /model.10/m/m.0/attn/MatMul
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SOFTMAX: /model.10/m/m.0/attn/Softmax
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] MATRIX_MULTIPLY: /model.10/m/m.0/attn/MatMul_1
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.10/m/m.0/attn/Reshape_2
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.23/Reshape
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] COPY: /model.23/Reshape_copy_output
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.23/Reshape_1
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] COPY: /model.23/Reshape_1_copy_output
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.23/Reshape_2
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] COPY: /model.23/Reshape_2_copy_output
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.23/dfl/Reshape + /model.23/dfl/Transpose
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SOFTMAX: /model.23/dfl/Softmax
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONVOLUTION: /model.23/dfl/conv/Conv
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONSTANT: scale_constant_of_/model.23/Sub_1
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONSTANT: scale_constant_of_/model.23/Sub
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] SHUFFLE: /model.23/dfl/Reshape_1
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONSTANT: /model.23/Constant_9_output_0
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONSTANT: /model.23/Constant_10_output_0
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] POINTWISE: PWN(scale_eltwise_of_/model.23/Sub, /model.23/Sub)
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] ELEMENTWISE: /model.23/Add_1
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] POINTWISE: PWN(scale_eltwise_of_/model.23/Sub_1, /model.23/Sub_1)
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] POINTWISE: PWN(/model.23/Constant_11_output_0 + (Unnamed Layer* 386) [Shuffle], PWN(/model.23/Add_2, /model.23/Div_1))
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] COPY: /model.23/Div_1_output_0 copy
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] CONSTANT: /model.23/Constant_12_output_0 + (Unnamed Layer* 390) [Shuffle]
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] POINTWISE: PWN(/model.23/Sigmoid)
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] ELEMENTWISE: /model.23/Mul_2
[01/23/2025-09:18:08] [I] [TRT] [GpuLayer] COPY: /model.23/Mul_2_output_0 copy
[01/23/2025-09:18:09] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +260, GPU +216, now: CPU 618, GPU 9068 (MiB)
[01/23/2025-09:18:09] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +82, GPU +78, now: CPU 700, GPU 9146 (MiB)
[01/23/2025-09:18:09] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[01/23/2025-09:21:01] [I] [TRT] Total Activation Memory: 32537235968
[01/23/2025-09:21:01] [I] [TRT] Detected 1 inputs and 3 output network tensors.
[01/23/2025-09:21:01] [I] [TRT] Total Host Persistent Memory: 12064
[01/23/2025-09:21:01] [I] [TRT] Total Device Persistent Memory: 0
[01/23/2025-09:21:01] [I] [TRT] Total Scratch Memory: 0
[01/23/2025-09:21:01] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 7 MiB, GPU 139 MiB
[01/23/2025-09:21:01] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 48 steps to complete.
[01/23/2025-09:21:01] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 7.02966ms to assign 9 blocks to 48 nodes requiring 15116800 bytes.
[01/23/2025-09:21:01] [I] [TRT] Total Activation Memory: 15116800
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 952, GPU 10253 (MiB)
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +7, GPU +4, now: CPU 7, GPU 4 (MiB)
[01/23/2025-09:21:02] [I] Engine built in 178.085 sec.
[01/23/2025-09:21:02] [I] [TRT] Loaded engine size: 7 MiB
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +0, now: CPU 843, GPU 10254 (MiB)
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +7, GPU +0, now: CPU 7, GPU 0 (MiB)
[01/23/2025-09:21:02] [I] Engine deserialized in 0.016784 sec.
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +0, now: CPU 843, GPU 10254 (MiB)
[01/23/2025-09:21:02] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +14, now: CPU 7, GPU 14 (MiB)
[01/23/2025-09:21:02] [I] Setting persistentCacheLimit to 0 bytes.
[01/23/2025-09:21:02] [I] Using random values for input images
[01/23/2025-09:21:02] [I] Created input binding for images with dimensions 1x3x640x640
[01/23/2025-09:21:02] [I] Using random values for output output0
[01/23/2025-09:21:02] [I] Created output binding for output0 with dimensions 1x12x8400
[01/23/2025-09:21:02] [I] Starting inference
[01/23/2025-09:21:05] [I] Warmup completed 9 queries over 200 ms
[01/23/2025-09:21:05] [I] Timing trace has 132 queries over 3.07944 s
[01/23/2025-09:21:05] [I] 
[01/23/2025-09:21:05] [I] === Trace details ===
[01/23/2025-09:21:05] [I] Trace averages of 10 runs:
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.1271 ms - Host latency: 23.3829 ms (enqueue 2.66291 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.4185 ms - Host latency: 23.68 ms (enqueue 2.64389 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 22.9784 ms - Host latency: 23.3299 ms (enqueue 2.66311 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.5607 ms - Host latency: 23.8015 ms (enqueue 3.10317 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.1228 ms - Host latency: 23.363 ms (enqueue 4.98899 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.5844 ms - Host latency: 23.8268 ms (enqueue 3.6684 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.334 ms - Host latency: 23.5707 ms (enqueue 2.83169 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 22.8815 ms - Host latency: 23.1272 ms (enqueue 2.79535 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.0527 ms - Host latency: 23.2955 ms (enqueue 2.59541 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.5917 ms - Host latency: 23.8439 ms (enqueue 2.6155 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 22.8305 ms - Host latency: 23.0741 ms (enqueue 2.51887 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 23.2034 ms - Host latency: 23.4582 ms (enqueue 2.60112 ms)
[01/23/2025-09:21:05] [I] Average on 10 runs - GPU latency: 22.3811 ms - Host latency: 22.6225 ms (enqueue 2.43613 ms)
[01/23/2025-09:21:05] [I] 
[01/23/2025-09:21:05] [I] === Performance summary ===
[01/23/2025-09:21:05] [I] Throughput: 42.8649 qps
[01/23/2025-09:21:05] [I] Latency: min = 22.3777 ms, max = 27.3136 ms, mean = 23.4075 ms, median = 23.1634 ms, percentile(90%) = 24.4261 ms, percentile(95%) = 25.0857 ms, percentile(99%) = 26.3242 ms
[01/23/2025-09:21:05] [I] Enqueue Time: min = 2.27856 ms, max = 10.9285 ms, mean = 2.92675 ms, median = 2.63731 ms, percentile(90%) = 3.29956 ms, percentile(95%) = 4.47388 ms, percentile(99%) = 7.9043 ms
[01/23/2025-09:21:05] [I] H2D Latency: min = 0.206177 ms, max = 1.29993 ms, mean = 0.231563 ms, median = 0.220215 ms, percentile(90%) = 0.236328 ms, percentile(95%) = 0.251465 ms, percentile(99%) = 0.288544 ms
[01/23/2025-09:21:05] [I] GPU Compute Time: min = 22.1396 ms, max = 27.0668 ms, mean = 23.1531 ms, median = 22.9154 ms, percentile(90%) = 24.1816 ms, percentile(95%) = 24.8416 ms, percentile(99%) = 26.0664 ms
[01/23/2025-09:21:05] [I] D2H Latency: min = 0.0151367 ms, max = 0.0361328 ms, mean = 0.0228789 ms, median = 0.0221558 ms, percentile(90%) = 0.0269165 ms, percentile(95%) = 0.0285645 ms, percentile(99%) = 0.03125 ms
[01/23/2025-09:21:05] [I] Total Host Walltime: 3.07944 s
[01/23/2025-09:21:05] [I] Total GPU Compute Time: 3.05621 s
[01/23/2025-09:21:05] [I] Explanations of the performance metrics are printed in the verbose logs.
[01/23/2025-09:21:05] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8502] # trtexec --onnx=2024_11_28_canicas_yolo11n.onnx --saveEngine=model_gn.engine --exportProfile=model_gn.json --fp16 --useDLACore=0 --allowGPUFallback --useSpinWait --separateProfileRun
